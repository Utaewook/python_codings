{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUgYoVqTGJzf"
      },
      "source": [
        "# Linear Regression : Single-variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjjTMVSDD81E"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbhaRLWZEFpJ",
        "outputId": "6c6617d1-2a7e-44f2-80bb-b806197952d0"
      },
      "source": [
        "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
        "t_data = np.array([2,3,4,5,6]).reshape(5,1)\n",
        "\n",
        "print(\"X_data = \", x_data.shape, \", t_data.shape = \", t_data.shape)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_data =  (5, 1) , t_data.shape =  (5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOok52MDEaJj",
        "outputId": "218ed978-b32e-4f86-bd48-22c3ab0ccce2"
      },
      "source": [
        "W = np.random.rand(1, 1)\n",
        "b = np.random.rand(1)\n",
        "\n",
        "print('W = ', W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W =  [[0.12646598]] , W.shape =  (1, 1) , b =  [0.85347697] , b.shape =  (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJbSNn7BEnm7"
      },
      "source": [
        "def loss_func(x, t):\n",
        "  y = np.dot(x, W) + b\n",
        "\n",
        "  return (np.sum((t-y)**2)) / len(x)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY9NnkF3EvRR"
      },
      "source": [
        "def numerical_derivative(f, x):\n",
        "  delta_x = 1e-4\n",
        "  grad = np.zeros_like(x)\n",
        "\n",
        "  it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "\n",
        "  while not it.finished:\n",
        "    idx = it.multi_index\n",
        "    tmp_val = x[idx]\n",
        "    x[idx] = float(tmp_val) + delta_x\n",
        "    fx1 = f(x)\n",
        "\n",
        "    x[idx] = tmp_val - delta_x\n",
        "    fx2 = f(x)\n",
        "    grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
        "\n",
        "    x[idx] = tmp_val\n",
        "    it.iternext()\n",
        "  return grad"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUZtWDZHFNSn"
      },
      "source": [
        "def error_val(x, t):\n",
        "  y = np.dot(x, W) + b\n",
        "  return (np.sum((t-y)**2)) / len(x)\n",
        "\n",
        "def predict(x):\n",
        "  y = np.dot(x, W) + b\n",
        "  return y"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogUsbgOhFWrr",
        "outputId": "4748103c-5290-45f2-f21d-35d7312aa3ac"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "f = lambda x : loss_func(x_data, t_data)\n",
        "\n",
        "print('Initial error value = ', error_val(x_data, t_data))\n",
        "print('Initial W = ', W, ', b = ', b)\n",
        "\n",
        "for step in range(10001):\n",
        "  W -= learning_rate * numerical_derivative(f, W)\n",
        "  b -= learning_rate * numerical_derivative(f, b)\n",
        "\n",
        "  if (step % 400 == 0):\n",
        "    print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial error value =  9.183104581770724\n",
            "Initial W =  [[0.12646598]] , b =  [0.85347697]\n",
            "step =  0 error value =  8.75438396294833 W =  [[0.14656287]] , b =  [0.85889064]\n",
            "step =  400 error value =  0.0009748101161550261 W =  [[0.97967158]] , b =  [1.07316396]\n",
            "step =  800 error value =  0.000743410007746994 W =  [[0.98229801]] , b =  [1.06390824]\n",
            "step =  1200 error value =  0.0005669701988005331 W =  [[0.98454077]] , b =  [1.05581139]\n",
            "step =  1600 error value =  0.0004324063480837245 W =  [[0.98649938]] , b =  [1.04874036]\n",
            "step =  2000 error value =  0.0003297796784710828 W =  [[0.98820984]] , b =  [1.0425652]\n",
            "step =  2400 error value =  0.0002515102676323822 W =  [[0.98970359]] , b =  [1.0371724]\n",
            "step =  2800 error value =  0.00019181720055579717 W =  [[0.9910081]] , b =  [1.03246284]\n",
            "step =  3200 error value =  0.0001462915958677364 W =  [[0.99214733]] , b =  [1.02834996]\n",
            "step =  3600 error value =  0.0001115709694413159 W =  [[0.99314222]] , b =  [1.02475816]\n",
            "step =  4000 error value =  8.509088405410313e-05 W =  [[0.99401107]] , b =  [1.02162142]\n",
            "step =  4400 error value =  6.489554214119379e-05 W =  [[0.99476984]] , b =  [1.01888209]\n",
            "step =  4800 error value =  4.949333217787891e-05 W =  [[0.99543247]] , b =  [1.01648982]\n",
            "step =  5200 error value =  3.774665946606785e-05 W =  [[0.99601116]] , b =  [1.01440065]\n",
            "step =  5600 error value =  2.878792431526174e-05 W =  [[0.99651652]] , b =  [1.01257615]\n",
            "step =  6000 error value =  2.1955441835228908e-05 W =  [[0.99695786]] , b =  [1.01098282]\n",
            "step =  6400 error value =  1.67445704282568e-05 W =  [[0.99734329]] , b =  [1.00959135]\n",
            "step =  6800 error value =  1.2770439371294621e-05 W =  [[0.99767988]] , b =  [1.00837617]\n",
            "step =  7200 error value =  9.739522577462302e-06 W =  [[0.99797383]] , b =  [1.00731495]\n",
            "step =  7600 error value =  7.427958998038706e-06 W =  [[0.99823053]] , b =  [1.00638818]\n",
            "step =  8000 error value =  5.6650184275151815e-06 W =  [[0.99845472]] , b =  [1.00557883]\n",
            "step =  8400 error value =  4.320491509520778e-06 W =  [[0.9986505]] , b =  [1.00487202]\n",
            "step =  8800 error value =  3.2950725796722974e-06 W =  [[0.99882147]] , b =  [1.00425476]\n",
            "step =  9200 error value =  2.513025029994764e-06 W =  [[0.99897078]] , b =  [1.0037157]\n",
            "step =  9600 error value =  1.9165874646718715e-06 W =  [[0.99910118]] , b =  [1.00324494]\n",
            "step =  10000 error value =  1.4617074903342119e-06 W =  [[0.99921506]] , b =  [1.00283382]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmhmyYsPF28-",
        "outputId": "1837800b-c848-4a8d-e301-fe599e9bff1e"
      },
      "source": [
        "predict(43)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[43.96908128]])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHNQVjdMGPka"
      },
      "source": [
        ">> ### 실습. 위 데이터를 예측을 잘 할 수 있도록, learning_rate 및 step을 수정해 볼 것."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeSlHbYlILHj"
      },
      "source": [
        "# Linear Regression : Multi-variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8y0_zwUGH2I"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbSXiGQVIQLF",
        "outputId": "6e6354ac-0e27-4fbc-9f9c-277f4608aee2"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/2021_2학기_데이터분석과머신러닝/LinearRegression_LogisticRegression"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/2021_2학기_데이터분석과머신러닝/LinearRegression_LogisticRegression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHwmFRhMIOk6",
        "outputId": "1c988853-3de1-4121-b916-ca61a96f9ecb"
      },
      "source": [
        "loaded_data = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
        "\n",
        "x_data = loaded_data[:, 0:-1]\n",
        "t_data = loaded_data[:, [-1]]\n",
        "\n",
        "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
        "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data.ndim =  2 , x_data.shape =  (25, 3)\n",
            "t_data.ndim =  2 , t_data.shape =  (25, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2REmozx8KWOl",
        "outputId": "5df393c3-dca8-4532-febc-e76132339d97"
      },
      "source": [
        "W = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "\n",
        "print('W = ', W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W =  [[0.16245252]\n",
            " [0.66909448]\n",
            " [0.62235649]] , W.shape =  (3, 1) , b =  [0.31324691] , b.shape =  (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LjF15wiKaKy"
      },
      "source": [
        "def loss_func(x, t):\n",
        "  y = np.dot(x, W) + b\n",
        "\n",
        "  return (np.sum((t-y)**2)) / len(x)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrwOqM2WKchl"
      },
      "source": [
        "def numerical_derivative(f, x):\n",
        "  delta_x = 1e-4\n",
        "  grad = np.zeros_like(x)\n",
        "\n",
        "  it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "\n",
        "  while not it.finished:\n",
        "    idx = it.multi_index\n",
        "    tmp_val = x[idx]\n",
        "    x[idx] = float(tmp_val) + delta_x\n",
        "    fx1 = f(x)\n",
        "\n",
        "    x[idx] = tmp_val - delta_x\n",
        "    fx2 = f(x)\n",
        "    grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
        "\n",
        "    x[idx] = tmp_val\n",
        "    it.iternext()\n",
        "  return grad"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UU-uf9cKd9f"
      },
      "source": [
        "def error_val(x, t):\n",
        "  y = np.dot(x, W) + b\n",
        "  return (np.sum((t-y)**2)) / len(x)\n",
        "\n",
        "def predict(x):\n",
        "  y = np.dot(x, W) + b\n",
        "  return y"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoburW__Kfw6",
        "outputId": "b9acf292-f82f-4b8f-d1de-8f7a77eec2a5"
      },
      "source": [
        "learning_rate = 1e-7\n",
        "f = lambda x : loss_func(x_data, t_data)\n",
        "\n",
        "print('Initial error value = ', error_val(x_data, t_data))\n",
        "print('Initial W = ', W, ', b = ', b)\n",
        "\n",
        "for step in range(50001):\n",
        "  W -= learning_rate * numerical_derivative(f, W)\n",
        "  b -= learning_rate * numerical_derivative(f, b)\n",
        "\n",
        "  if (step % 400 == 0):\n",
        "    print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial error value =  2080.9167356159624\n",
            "Initial W =  [[0.16245252]\n",
            " [0.66909448]\n",
            " [0.62235649]] , b =  [0.31324691]\n",
            "step =  0 error value =  2064.719851406686 W =  [[0.16317957]\n",
            " [0.66982413]\n",
            " [0.62310601]] , b =  [0.31325587]\n",
            "step =  400 error value =  99.39400878133692 W =  [[0.30953981]\n",
            " [0.81642802]\n",
            " [0.77427268]] , b =  [0.31505869]\n",
            "step =  800 error value =  14.462005958374917 W =  [[0.33995769]\n",
            " [0.84645248]\n",
            " [0.80613883]] , b =  [0.31543061]\n",
            "step =  1200 error value =  10.777140163669378 W =  [[0.34627535]\n",
            " [0.85224505]\n",
            " [0.81320589]] , b =  [0.3155051]\n",
            "step =  1600 error value =  10.602812395112828 W =  [[0.34758346]\n",
            " [0.85300148]\n",
            " [0.81511732]] , b =  [0.31551776]\n",
            "step =  2000 error value =  10.580219747425069 W =  [[0.34785029]\n",
            " [0.85271185]\n",
            " [0.81595628]] , b =  [0.31551756]\n",
            "step =  2400 error value =  10.564236611544223 W =  [[0.3479007 ]\n",
            " [0.85220557]\n",
            " [0.81657153]] , b =  [0.31551469]\n",
            "step =  2800 error value =  10.548592285193964 W =  [[0.34790615]\n",
            " [0.85165504]\n",
            " [0.81713948]] , b =  [0.31551125]\n",
            "step =  3200 error value =  10.533015638119425 W =  [[0.34790228]\n",
            " [0.8510961 ]\n",
            " [0.81769681]] , b =  [0.31550769]\n",
            "step =  3600 error value =  10.517494767232732 W =  [[0.3478965 ]\n",
            " [0.85053618]\n",
            " [0.81825114]] , b =  [0.3155041]\n",
            "step =  4000 error value =  10.502028970687464 W =  [[0.34789035]\n",
            " [0.84997685]\n",
            " [0.81880407]] , b =  [0.3155005]\n",
            "step =  4400 error value =  10.486618031284396 W =  [[0.34788414]\n",
            " [0.84941841]\n",
            " [0.81935592]] , b =  [0.31549689]\n",
            "step =  4800 error value =  10.471261753428667 W =  [[0.34787795]\n",
            " [0.84886094]\n",
            " [0.81990676]] , b =  [0.31549327]\n",
            "step =  5200 error value =  10.455959943120098 W =  [[0.34787179]\n",
            " [0.84830444]\n",
            " [0.82045661]] , b =  [0.31548965]\n",
            "step =  5600 error value =  10.44071240708576 W =  [[0.34786566]\n",
            " [0.84774892]\n",
            " [0.82100547]] , b =  [0.31548602]\n",
            "step =  6000 error value =  10.425518952740596 W =  [[0.34785955]\n",
            " [0.84719438]\n",
            " [0.82155335]] , b =  [0.31548239]\n",
            "step =  6400 error value =  10.4103793881829 W =  [[0.34785348]\n",
            " [0.84664081]\n",
            " [0.82210024]] , b =  [0.31547875]\n",
            "step =  6800 error value =  10.395293522192071 W =  [[0.34784744]\n",
            " [0.84608822]\n",
            " [0.82264616]] , b =  [0.3154751]\n",
            "step =  7200 error value =  10.380261164226331 W =  [[0.34784144]\n",
            " [0.84553659]\n",
            " [0.8231911 ]] , b =  [0.31547145]\n",
            "step =  7600 error value =  10.365282124419856 W =  [[0.34783546]\n",
            " [0.84498593]\n",
            " [0.82373505]] , b =  [0.31546778]\n",
            "step =  8000 error value =  10.350356213580854 W =  [[0.34782951]\n",
            " [0.84443624]\n",
            " [0.82427804]] , b =  [0.31546412]\n",
            "step =  8400 error value =  10.33548324318892 W =  [[0.3478236 ]\n",
            " [0.84388752]\n",
            " [0.82482005]] , b =  [0.31546044]\n",
            "step =  8800 error value =  10.320663025392712 W =  [[0.34781771]\n",
            " [0.84333976]\n",
            " [0.82536108]] , b =  [0.31545676]\n",
            "step =  9200 error value =  10.30589537300747 W =  [[0.34781186]\n",
            " [0.84279296]\n",
            " [0.82590115]] , b =  [0.31545308]\n",
            "step =  9600 error value =  10.291180099512992 W =  [[0.34780604]\n",
            " [0.84224713]\n",
            " [0.82644025]] , b =  [0.31544939]\n",
            "step =  10000 error value =  10.276517019050834 W =  [[0.34780025]\n",
            " [0.84170225]\n",
            " [0.82697838]] , b =  [0.31544569]\n",
            "step =  10400 error value =  10.26190594642228 W =  [[0.34779449]\n",
            " [0.84115833]\n",
            " [0.82751555]] , b =  [0.31544198]\n",
            "step =  10800 error value =  10.24734669708578 W =  [[0.34778876]\n",
            " [0.84061537]\n",
            " [0.82805175]] , b =  [0.31543827]\n",
            "step =  11200 error value =  10.232839087154801 W =  [[0.34778306]\n",
            " [0.84007336]\n",
            " [0.82858699]] , b =  [0.31543455]\n",
            "step =  11600 error value =  10.218382933395441 W =  [[0.34777739]\n",
            " [0.8395323 ]\n",
            " [0.82912128]] , b =  [0.31543083]\n",
            "step =  12000 error value =  10.203978053224006 W =  [[0.34777175]\n",
            " [0.83899219]\n",
            " [0.8296546 ]] , b =  [0.3154271]\n",
            "step =  12400 error value =  10.189624264704843 W =  [[0.34776614]\n",
            " [0.83845303]\n",
            " [0.83018697]] , b =  [0.31542337]\n",
            "step =  12800 error value =  10.175321386547965 W =  [[0.34776056]\n",
            " [0.83791482]\n",
            " [0.83071838]] , b =  [0.31541962]\n",
            "step =  13200 error value =  10.161069238106846 W =  [[0.34775501]\n",
            " [0.83737755]\n",
            " [0.83124884]] , b =  [0.31541587]\n",
            "step =  13600 error value =  10.146867639376 W =  [[0.34774949]\n",
            " [0.83684123]\n",
            " [0.83177835]] , b =  [0.31541212]\n",
            "step =  14000 error value =  10.1327164109888 W =  [[0.347744  ]\n",
            " [0.83630585]\n",
            " [0.8323069 ]] , b =  [0.31540836]\n",
            "step =  14400 error value =  10.118615374215253 W =  [[0.34773854]\n",
            " [0.83577141]\n",
            " [0.83283451]] , b =  [0.31540459]\n",
            "step =  14800 error value =  10.10456435095953 W =  [[0.34773311]\n",
            " [0.83523791]\n",
            " [0.83336118]] , b =  [0.31540082]\n",
            "step =  15200 error value =  10.090563163758029 W =  [[0.34772771]\n",
            " [0.83470534]\n",
            " [0.8338869 ]] , b =  [0.31539704]\n",
            "step =  15600 error value =  10.076611635776874 W =  [[0.34772234]\n",
            " [0.83417371]\n",
            " [0.83441167]] , b =  [0.31539325]\n",
            "step =  16000 error value =  10.06270959080975 W =  [[0.347717  ]\n",
            " [0.83364302]\n",
            " [0.83493551]] , b =  [0.31538946]\n",
            "step =  16400 error value =  10.04885685327576 W =  [[0.34771169]\n",
            " [0.83311326]\n",
            " [0.8354584 ]] , b =  [0.31538566]\n",
            "step =  16800 error value =  10.035053248217071 W =  [[0.34770641]\n",
            " [0.83258443]\n",
            " [0.83598036]] , b =  [0.31538186]\n",
            "step =  17200 error value =  10.021298601296873 W =  [[0.34770116]\n",
            " [0.83205652]\n",
            " [0.83650138]] , b =  [0.31537805]\n",
            "step =  17600 error value =  10.00759273879697 W =  [[0.34769593]\n",
            " [0.83152955]\n",
            " [0.83702147]] , b =  [0.31537423]\n",
            "step =  18000 error value =  9.993935487615733 W =  [[0.34769074]\n",
            " [0.8310035 ]\n",
            " [0.83754062]] , b =  [0.31537041]\n",
            "step =  18400 error value =  9.980326675265891 W =  [[0.34768557]\n",
            " [0.83047837]\n",
            " [0.83805885]] , b =  [0.31536658]\n",
            "step =  18800 error value =  9.966766129872262 W =  [[0.34768044]\n",
            " [0.82995417]\n",
            " [0.83857614]] , b =  [0.31536275]\n",
            "step =  19200 error value =  9.953253680169723 W =  [[0.34767533]\n",
            " [0.82943088]\n",
            " [0.8390925 ]] , b =  [0.31535891]\n",
            "step =  19600 error value =  9.939789155500877 W =  [[0.34767025]\n",
            " [0.82890852]\n",
            " [0.83960794]] , b =  [0.31535506]\n",
            "step =  20000 error value =  9.926372385814085 W =  [[0.34766521]\n",
            " [0.82838707]\n",
            " [0.84012246]] , b =  [0.31535121]\n",
            "step =  20400 error value =  9.913003201661107 W =  [[0.34766019]\n",
            " [0.82786654]\n",
            " [0.84063605]] , b =  [0.31534735]\n",
            "step =  20800 error value =  9.899681434195134 W =  [[0.34765519]\n",
            " [0.82734693]\n",
            " [0.84114872]] , b =  [0.31534349]\n",
            "step =  21200 error value =  9.88640691516866 W =  [[0.34765023]\n",
            " [0.82682822]\n",
            " [0.84166047]] , b =  [0.31533962]\n",
            "step =  21600 error value =  9.873179476931096 W =  [[0.3476453 ]\n",
            " [0.82631043]\n",
            " [0.8421713 ]] , b =  [0.31533574]\n",
            "step =  22000 error value =  9.859998952426993 W =  [[0.34764039]\n",
            " [0.82579355]\n",
            " [0.84268122]] , b =  [0.31533186]\n",
            "step =  22400 error value =  9.846865175193779 W =  [[0.34763551]\n",
            " [0.82527757]\n",
            " [0.84319022]] , b =  [0.31532797]\n",
            "step =  22800 error value =  9.833777979359564 W =  [[0.34763066]\n",
            " [0.82476251]\n",
            " [0.84369831]] , b =  [0.31532408]\n",
            "step =  23200 error value =  9.820737199641156 W =  [[0.34762584]\n",
            " [0.82424834]\n",
            " [0.84420549]] , b =  [0.31532018]\n",
            "step =  23600 error value =  9.807742671342 W =  [[0.34762105]\n",
            " [0.82373508]\n",
            " [0.84471176]] , b =  [0.31531627]\n",
            "step =  24000 error value =  9.794794230349941 W =  [[0.34761629]\n",
            " [0.82322272]\n",
            " [0.84521712]] , b =  [0.31531236]\n",
            "step =  24400 error value =  9.781891713135337 W =  [[0.34761155]\n",
            " [0.82271126]\n",
            " [0.84572157]] , b =  [0.31530844]\n",
            "step =  24800 error value =  9.769034956748856 W =  [[0.34760684]\n",
            " [0.8222007 ]\n",
            " [0.84622512]] , b =  [0.31530452]\n",
            "step =  25200 error value =  9.756223798819603 W =  [[0.34760216]\n",
            " [0.82169103]\n",
            " [0.84672776]] , b =  [0.31530059]\n",
            "step =  25600 error value =  9.743458077552706 W =  [[0.34759751]\n",
            " [0.82118226]\n",
            " [0.8472295 ]] , b =  [0.31529665]\n",
            "step =  26000 error value =  9.730737631727617 W =  [[0.34759288]\n",
            " [0.82067439]\n",
            " [0.84773035]] , b =  [0.31529271]\n",
            "step =  26400 error value =  9.718062300696023 W =  [[0.34758829]\n",
            " [0.8201674 ]\n",
            " [0.84823029]] , b =  [0.31528876]\n",
            "step =  26800 error value =  9.70543192437957 W =  [[0.34758372]\n",
            " [0.81966131]\n",
            " [0.84872934]] , b =  [0.31528481]\n",
            "step =  27200 error value =  9.692846343268158 W =  [[0.34757918]\n",
            " [0.8191561 ]\n",
            " [0.84922749]] , b =  [0.31528085]\n",
            "step =  27600 error value =  9.680305398417707 W =  [[0.34757466]\n",
            " [0.81865179]\n",
            " [0.84972475]] , b =  [0.31527689]\n",
            "step =  28000 error value =  9.667808931448223 W =  [[0.34757018]\n",
            " [0.81814835]\n",
            " [0.85022112]] , b =  [0.31527292]\n",
            "step =  28400 error value =  9.655356784541844 W =  [[0.34756572]\n",
            " [0.81764581]\n",
            " [0.85071659]] , b =  [0.31526894]\n",
            "step =  28800 error value =  9.642948800440733 W =  [[0.34756128]\n",
            " [0.81714414]\n",
            " [0.85121118]] , b =  [0.31526496]\n",
            "step =  29200 error value =  9.630584822445165 W =  [[0.34755688]\n",
            " [0.81664336]\n",
            " [0.85170488]] , b =  [0.31526097]\n",
            "step =  29600 error value =  9.618264694411563 W =  [[0.3475525 ]\n",
            " [0.81614345]\n",
            " [0.85219769]] , b =  [0.31525698]\n",
            "step =  30000 error value =  9.605988260750546 W =  [[0.34754815]\n",
            " [0.81564442]\n",
            " [0.85268962]] , b =  [0.31525298]\n",
            "step =  30400 error value =  9.5937553664248 W =  [[0.34754383]\n",
            " [0.81514627]\n",
            " [0.85318067]] , b =  [0.31524897]\n",
            "step =  30800 error value =  9.581565856947247 W =  [[0.34753953]\n",
            " [0.814649  ]\n",
            " [0.85367084]] , b =  [0.31524496]\n",
            "step =  31200 error value =  9.569419578379085 W =  [[0.34753526]\n",
            " [0.81415259]\n",
            " [0.85416012]] , b =  [0.31524094]\n",
            "step =  31600 error value =  9.557316377327874 W =  [[0.34753102]\n",
            " [0.81365706]\n",
            " [0.85464853]] , b =  [0.31523692]\n",
            "step =  32000 error value =  9.545256100945494 W =  [[0.3475268 ]\n",
            " [0.8131624 ]\n",
            " [0.85513607]] , b =  [0.31523289]\n",
            "step =  32400 error value =  9.533238596926298 W =  [[0.34752261]\n",
            " [0.81266861]\n",
            " [0.85562272]] , b =  [0.31522886]\n",
            "step =  32800 error value =  9.521263713505185 W =  [[0.34751845]\n",
            " [0.81217568]\n",
            " [0.85610851]] , b =  [0.31522482]\n",
            "step =  33200 error value =  9.509331299455647 W =  [[0.34751431]\n",
            " [0.81168362]\n",
            " [0.85659342]] , b =  [0.31522078]\n",
            "step =  33600 error value =  9.497441204087812 W =  [[0.3475102 ]\n",
            " [0.81119243]\n",
            " [0.85707747]] , b =  [0.31521673]\n",
            "step =  34000 error value =  9.485593277246647 W =  [[0.34750612]\n",
            " [0.81070209]\n",
            " [0.85756064]] , b =  [0.31521267]\n",
            "step =  34400 error value =  9.47378736931003 W =  [[0.34750206]\n",
            " [0.81021262]\n",
            " [0.85804295]] , b =  [0.31520861]\n",
            "step =  34800 error value =  9.46202333118674 W =  [[0.34749803]\n",
            " [0.80972401]\n",
            " [0.85852439]] , b =  [0.31520454]\n",
            "step =  35200 error value =  9.450301014314793 W =  [[0.34749403]\n",
            " [0.80923625]\n",
            " [0.85900497]] , b =  [0.31520047]\n",
            "step =  35600 error value =  9.438620270659301 W =  [[0.34749005]\n",
            " [0.80874935]\n",
            " [0.85948469]] , b =  [0.31519639]\n",
            "step =  36000 error value =  9.426980952710895 W =  [[0.3474861 ]\n",
            " [0.80826331]\n",
            " [0.85996354]] , b =  [0.3151923]\n",
            "step =  36400 error value =  9.415382913483581 W =  [[0.34748217]\n",
            " [0.80777812]\n",
            " [0.86044154]] , b =  [0.31518821]\n",
            "step =  36800 error value =  9.403826006513093 W =  [[0.34747827]\n",
            " [0.80729378]\n",
            " [0.86091868]] , b =  [0.31518412]\n",
            "step =  37200 error value =  9.39231008585488 W =  [[0.3474744 ]\n",
            " [0.80681029]\n",
            " [0.86139496]] , b =  [0.31518002]\n",
            "step =  37600 error value =  9.380835006082323 W =  [[0.34747055]\n",
            " [0.80632765]\n",
            " [0.86187039]] , b =  [0.31517591]\n",
            "step =  38000 error value =  9.369400622284981 W =  [[0.34746673]\n",
            " [0.80584586]\n",
            " [0.86234496]] , b =  [0.3151718]\n",
            "step =  38400 error value =  9.358006790066685 W =  [[0.34746293]\n",
            " [0.80536492]\n",
            " [0.86281869]] , b =  [0.31516768]\n",
            "step =  38800 error value =  9.346653365543679 W =  [[0.34745916]\n",
            " [0.80488481]\n",
            " [0.86329156]] , b =  [0.31516356]\n",
            "step =  39200 error value =  9.335340205342803 W =  [[0.34745542]\n",
            " [0.80440556]\n",
            " [0.86376359]] , b =  [0.31515943]\n",
            "step =  39600 error value =  9.324067166599786 W =  [[0.3474517 ]\n",
            " [0.80392714]\n",
            " [0.86423476]] , b =  [0.31515529]\n",
            "step =  40000 error value =  9.312834106957297 W =  [[0.347448  ]\n",
            " [0.80344956]\n",
            " [0.8647051 ]] , b =  [0.31515115]\n",
            "step =  40400 error value =  9.301640884563287 W =  [[0.34744433]\n",
            " [0.80297282]\n",
            " [0.86517458]] , b =  [0.31514701]\n",
            "step =  40800 error value =  9.290487358069118 W =  [[0.34744069]\n",
            " [0.80249692]\n",
            " [0.86564323]] , b =  [0.31514286]\n",
            "step =  41200 error value =  9.279373386627748 W =  [[0.34743707]\n",
            " [0.80202185]\n",
            " [0.86611103]] , b =  [0.3151387]\n",
            "step =  41600 error value =  9.268298829891949 W =  [[0.34743348]\n",
            " [0.80154762]\n",
            " [0.866578  ]] , b =  [0.31513454]\n",
            "step =  42000 error value =  9.257263548012684 W =  [[0.34742991]\n",
            " [0.80107422]\n",
            " [0.86704413]] , b =  [0.31513037]\n",
            "step =  42400 error value =  9.246267401637093 W =  [[0.34742637]\n",
            " [0.80060165]\n",
            " [0.86750942]] , b =  [0.3151262]\n",
            "step =  42800 error value =  9.235310251907029 W =  [[0.34742285]\n",
            " [0.80012992]\n",
            " [0.86797388]] , b =  [0.31512202]\n",
            "step =  43200 error value =  9.224391960456943 W =  [[0.34741936]\n",
            " [0.79965901]\n",
            " [0.8684375 ]] , b =  [0.31511784]\n",
            "step =  43600 error value =  9.213512389412418 W =  [[0.34741589]\n",
            " [0.79918892]\n",
            " [0.86890029]] , b =  [0.31511365]\n",
            "step =  44000 error value =  9.20267140138846 W =  [[0.34741245]\n",
            " [0.79871966]\n",
            " [0.86936225]] , b =  [0.31510945]\n",
            "step =  44400 error value =  9.191868859487412 W =  [[0.34740903]\n",
            " [0.79825123]\n",
            " [0.86982338]] , b =  [0.31510525]\n",
            "step =  44800 error value =  9.181104627297618 W =  [[0.34740563]\n",
            " [0.79778362]\n",
            " [0.87028368]] , b =  [0.31510105]\n",
            "step =  45200 error value =  9.170378568891458 W =  [[0.34740226]\n",
            " [0.79731682]\n",
            " [0.87074316]] , b =  [0.31509684]\n",
            "step =  45600 error value =  9.159690548823724 W =  [[0.34739892]\n",
            " [0.79685085]\n",
            " [0.87120181]] , b =  [0.31509262]\n",
            "step =  46000 error value =  9.14904043212989 W =  [[0.3473956 ]\n",
            " [0.7963857 ]\n",
            " [0.87165964]] , b =  [0.3150884]\n",
            "step =  46400 error value =  9.13842808432438 W =  [[0.3473923 ]\n",
            " [0.79592136]\n",
            " [0.87211665]] , b =  [0.31508417]\n",
            "step =  46800 error value =  9.127853371398919 W =  [[0.34738903]\n",
            " [0.79545784]\n",
            " [0.87257284]] , b =  [0.31507994]\n",
            "step =  47200 error value =  9.117316159820795 W =  [[0.34738579]\n",
            " [0.79499513]\n",
            " [0.87302821]] , b =  [0.3150757]\n",
            "step =  47600 error value =  9.106816316531205 W =  [[0.34738256]\n",
            " [0.79453323]\n",
            " [0.87348276]] , b =  [0.31507146]\n",
            "step =  48000 error value =  9.096353708943484 W =  [[0.34737937]\n",
            " [0.79407215]\n",
            " [0.8739365 ]] , b =  [0.31506721]\n",
            "step =  48400 error value =  9.085928204941592 W =  [[0.34737619]\n",
            " [0.79361187]\n",
            " [0.87438942]] , b =  [0.31506296]\n",
            "step =  48800 error value =  9.07553967287832 W =  [[0.34737304]\n",
            " [0.7931524 ]\n",
            " [0.87484153]] , b =  [0.3150587]\n",
            "step =  49200 error value =  9.065187981573619 W =  [[0.34736991]\n",
            " [0.79269374]\n",
            " [0.87529283]] , b =  [0.31505444]\n",
            "step =  49600 error value =  9.054873000313087 W =  [[0.34736681]\n",
            " [0.79223588]\n",
            " [0.87574331]] , b =  [0.31505017]\n",
            "step =  50000 error value =  9.04459459884599 W =  [[0.34736373]\n",
            " [0.79177883]\n",
            " [0.87619299]] , b =  [0.31504589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khTjhsq1Kha4",
        "outputId": "89fcf1f6-60b9-4a39-b5d3-bb6fa902883e"
      },
      "source": [
        "test_data = np.array([100, 98, 81])\n",
        "predict(test_data)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([183.61737697])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiS3lyXZLwwo"
      },
      "source": [
        ">> ### 실습. 위 코드에서 학습률이 1e-5일 때, 10,000 step을 한 경우와, 1e-3일 때, 10,000과 50,000 step을 진행한 경우의 결과를 확인하라."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du_qCJHefBhV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}